[Server] collection_manager listening on /tmp/collection_manager.sock
[Server] Received message: {"type": "add_class", "class_name": "market_collector", "code": "import asyncio\nimport aiohttp\nimport sqlite3\nimport json\nimport os\nfrom datetime import datetime, timezone\nimport time\nimport shutil\n\nclass market_collector:\n    def __init__(self, data_dir=\"data\", verbosity=\"DEBUG\", reset=True, batch_size=500, reset_offset=108000, init_offset=108000):\n        # sql resources\n        self.__data_dir = data_dir\n        self.__markets_dir = None\n        self.__markets_db = None # overview db\n        self.__market_ids = []\n        self.__attributes_db = None\n        self.__reset = reset\n\n        # attribute handling\n        self.__primary_attributes = [\"id\", \"clobTokenIds\", \"negRiskMarketID\"]\n        self.__attributes = {}\n\n        # logging\n        self.__verbosity = verbosity.upper()\n\n        # markets endpoint\n        self.__markets_url = \"https://gamma-api.polymarket.com/markets?limit=500&offset={offset}\"\n        self.__markets_cli = None\n        self.__market_offset = init_offset\n        self.__reset_offset = reset_offset\n        self.__rate_limit = 100 * 1000 * 1000 # 100ms or 100 * 1000^2 ns\n        self.__last_request = -self.__rate_limit\n        self.__batch_size = batch_size\n\n        # liveness\n        self.__running = False\n\n        # version\n        self.__version = 1\n\n    def change_settings(\n        self, \n        verbosity=None,\n        markets_url=None,\n        reset_offset=None,\n        rate_limit=None,\n        batch_size=None,\n        version=None\n    ):\n        if verbosity is not None:\n            self.__verbosity = verbosity\n        if markets_url is not None:\n            self.__markets_url = markets_url\n        if reset_offset is not None:\n            self.__reset_offset = reset_offset\n        if rate_limit is not None:\n            self.__rate_limit = rate_limit\n        if batch_size is not None:\n            self.__batch_size = batch_size\n        if version is not None:\n            self.__version = version\n\n    \n    async def start(self)->bool:\n        # Can't start if already running\n        if self.__running:\n            self.__log(\"market_collector already started\", \"ERROR\")\n            return False\n        try:\n            # Ensure directories exists \n            os.makedirs(self.__data_dir, exist_ok=True)\n            self.__markets_dir = os.path.join(self.__data_dir, \"markets\")\n\n            # clear all markets data\n            if self.__reset and os.path.exists(self.__markets_dir):\n                shutil.rmtree(self.__markets_dir)\n                self.__markets_dir = os.path.join(self.__data_dir, \"markets\")\n\n            # create markets db if it doesn't exist\n            os.makedirs(self.__markets_dir, exist_ok=True)\n            markets_db_path = os.path.join(self.__markets_dir, \"markets.db\")\n            attributes_db_path = os.path.join(self.__markets_dir, \"attributes.db\")\n\n            # Store persistent connection to markets db\n            self.__attributes_db = sqlite3.connect(attributes_db_path)\n            self.__markets_db = sqlite3.connect(markets_db_path)\n            cur = self.__markets_db.cursor()\n\n            cur.executescript(\"\"\"\n                CREATE TABLE IF NOT EXISTS markets  (\n                    row_index INTEGER PRIMARY KEY AUTOINCREMENT,\n                    collector_version INTEGER,\n                    insert_time TEXT,\n                    id TEXT,\n                    clobTokenIds1 TEXT,\n                    clobTokenIds2 TEXT,\n                    negRiskMarketID TEXT --can be NULL\n                );\n                CREATE TABLE IF NOT EXISTS attributes  (\n                    row_index INTEGER PRIMARY KEY AUTOINCREMENT,\n                    collector_version INTEGER,\n                    insert_time TEXT,\n                    attribute_name TEXT\n                );\n            \"\"\")\n            self.__markets_db.commit()\n        except (OSError, sqlite3.Error) as e:\n            self.__log(f\"market_collector to start: {e}\", \"ERROR\")\n            return False\n\n        # At most 3 sockets for pipeling and keepalive forever\n        connector = aiohttp.TCPConnector(limit_per_host=2, keepalive_timeout=99999)\n        self.__markets_cli = aiohttp.ClientSession(connector=connector)\n        \n        self.__running = True\n        self.__log(\"market_collector started\", \"INFO\")\n\n        while self.__running:\n            now = time.monotonic_ns()\n            should_be = self.__last_request + self.__rate_limit\n            if should_be > now:\n                await asyncio.sleep((should_be - now) / 1_000_000_000)\n            self.__last_request = time.monotonic_ns()\n            if not await self.__query_markets():\n                self.__log(f\"market_collector exiting running loop due to abort\", \"DEBUG\")\n                await self.__clean_up()\n                return False\n\n    async def stop(self)->bool:\n        await self.__clean_up()\n        self.__log(\"market_collector stopped\", \"DEBUG\")\n        return True;\n\n    async def __clean_up(self):\n        self.__log(\"market_collector cleanup started\", \"DEBUG\")\n\n        # Close aiohttp client\n        if self.__markets_cli is not None:\n            try:\n                await self.__markets_cli.close()\n                self.__log(\"Closed markets aiohttp client\", \"DEBUG\")\n            except Exception as e:\n                self.__log(f\"Error closing markets aiohttp client: {e}\", \"ERROR\")\n            self.__markets_cli = None\n\n\n        # Close main markets.db\n        if self.__markets_db is not None:\n            try:\n                self.__markets_db.close()\n                self.__log(\"Closed markets.db connection\", \"DEBUG\")\n            except Exception as e:\n                self.__log(f\"Error closing markets.db: {e}\", \"ERROR\")\n            self.__markets_db = None\n\n        # Close all atttibutes db\n        if self.__attributes_db is not None:\n            try:\n                self.__attributes_db.close()\n                self.__log(\"Closed markets.db connection\", \"DEBUG\")\n            except Exception as e:\n                self.__log(f\"Error closing markets.db: {e}\", \"ERROR\")\n            self.__attributes_db = None\n\n        self.__running = False\n\n        self.__log(\"market_collector cleanup finished\", \"INFO\")\n\n    def __log(self, msg, level=\"INFO\"):\n        levels = [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"]\n        if levels.index(level) >= levels.index(self.__verbosity):\n            print(f\"[{level}] {msg}\")\n\n    def __set_attribute(self, name, value) -> bool:\n        if isinstance(value, bool):\n            self.__attributes[name][0] = \"BOOL\"\n            self.__attributes[name][1] = value\n            return True\n        elif isinstance(value, int):\n            # Check if the integer fits in SQLite INTEGER (64-bit signed)\n            if -(2**63) <= value <= 2**63 - 1:\n                self.__attributes[name][0] = \"INTEGER\"\n                self.__attributes[name][1] = value\n                return True\n            self.__attributes[name][0] = \"TEXT\"\n            self.__attributes[name][1] = str(value)\n            return True # too large, store as string\n        elif isinstance(value, float):\n            self.__attributes[name][0] = \"REAL\"\n            self.__attributes[name][1] = value\n        elif isinstance(value, str):\n            self.__attributes[name][0] = \"TEXT\"\n            if value == \"\":\n                self.__attributes[name][1] = \"NULL\"\n            else:\n                self.__attributes[name][1] = value\n            return True\n        elif value is None:\n            # keep same type as before\n            self.__attributes[name][1] = \"NULL\"\n        else:\n            return False\n\n    def __handle_attribute(self, name, value) -> bool:\n        if name in self.__attributes:\n            if len(self.__attributes[name]) != 2:\n                self.__log(f\"market collector handle_attribute name {name} registered with incorrect list length {len(self.__attributes[name])}\", \"ERROR\")\n                return False\n            if not self.__set_attribute(name, value):\n                return False\n            return True\n\n        try:\n            value = json.loads(value)\n        except (json.JSONDecodeError, TypeError):\n            pass\n\n        if isinstance(value, list):\n            for i, subvalue in enumerate(value, start=1):\n                if not self.__handle_attribute(f\"{name}{i}\", subvalue):\n                    self.__log(f\"market collector handle_attribute failed for list element {i} of {name}\", \"ERROR\")\n                    return False\n            return True\n        elif isinstance(value, dict):\n            for subkey, subvalue in value.items():\n                if not self.__handle_attribute(subkey, subvalue):\n                    self.__log(f\"market collector handle_attribute failed for dict key {subkey} of {name}\", \"ERROR\")\n                    return False\n            return True\n\n        self.__attributes[name] = [\"TEXT\", \"NULL\"] # default\n        if not self.__set_attribute(name, value):\n            self.__log(f\"market_collector failed to set_attribute for {name} and {value} of type {type(value)}\", \"ERROR\")\n            return False\n        try:\n            cursor = self.__attributes_db.cursor()\n            cursor.executescript(self.__create_alter_stmt(name, self.__attributes[name][0]))\n            self.__attributes_db.commit()\n        except Exception as e:\n            self.__log(f\"market_collector add column of type {self.__attributes[name][0]}: {e}\", \"ERROR\")\n            return False\n        return True\n\n    async def __query_markets(self)->bool:\n        url = self.__markets_url.format(offset=self.__market_offset)\n        try:\n            # Reuse the same session -> TCP + TLS persistent\n            resp = await self.__markets_cli.get(url)\n            if resp.status != 200:\n                self.__log(f\"market fetch failed: {resp.status}\", \"ERROR\")\n                await resp.release()\n                return False\n\n            market_arr = await resp.json()\n            await resp.release()  # release the connection back to the pool\n\n            # Process markets here\n        except aiohttp.ClientError as e:\n            self.__log(f\"HTTP request failed: {e}\", \"ERROR\")\n            return False\n        self.__log(f\"market_collector fetched {len(market_arr)} markets\", \"DEBUG\")\n\n        if not isinstance(market_arr, list):\n            self.__log(f\"market_collector market response not list but {type(market_arr)}\", \"ERROR\")\n            return False\n\n        for market_obj in market_arr: \n            if not isinstance(market_obj, dict):\n                self.__log(f\"market_collector market_obj is not dict but {type(market_obj)}\", \"ERROR\")\n                return False\n\n            for key, value in market_obj.items():\n                if not self.__handle_attribute(key, value):\n                    return False\n            \n            if not self.__handle_query():\n                return False\n\n        new_markets = len(market_arr)\n        self.__log(f\"market_collector {new_markets} markets fetched at offset {self.__market_offset}\")\n        if new_markets < self.__batch_size:\n            self.__market_offset = self.__reset_offset\n        else:\n            self.__market_offset += new_markets\n        return True\n\n    def __create_alter_stmt(self, attr_name, attr_sql_type, default=\"NULL\")->str:\n        buffer = []\n        for market_id in self.__market_ids:\n            buffer.append(f\"ALTER TABLE {market_id} ADD {attr_name} {attr_sql_type};\")\n        \n        return \"\".join(buffer)\n        \n    def __create_table_stmt(self, market_id) -> str:\n        buffer = [f\"CREATE TABLE IF NOT EXISTS {market_id} (row_index INTEGER PRIMARY KEY AUTOINCREMENT, collector_version INTEGER, insert_time TEXT\"]\n        for name, attr in self.__attributes.items():\n            buffer.append(f\"{name} {attr[0]}\")\n        buffer.append(')')\n        return \"\".join(buffer)\n\n    def __create_insert_stmt(self, market_id) -> str:\n        now = datetime.now(timezone.utc)\n        iso_str = now.isoformat(timespec=\"microseconds\").replace(\"+00:00\", \"Z\")\n\n        # Column list\n        columns = [\"collector_version\", \"insert_time\"] + list(self.__attributes.keys())\n        buffer = [f\"INSERT INTO {market_id} ({', '.join(columns)}) VALUES (\"]\n\n        # Value list\n        values = [str(self.__version), f\"'{iso_str}'\"]\n        for _, attr in self.__attributes.items():\n            if attr[1] == \"NULL\":\n                values.append(\"NULL\")\n            elif attr[0] == \"TEXT\":\n                values.append(f\"'{attr[1]}'\")\n            else:\n                values.append(str(attr[1]))\n\n        buffer.append(\", \".join(values))\n        buffer.append(\")\")\n\n        return \"\".join(buffer)\n\n    def __handle_query(self) -> bool:\n        market_id = self.__attributes.get(\"id\", [None, None])[1]\n        if market_id is None:\n            self.__log(\"market collector handle_query failed: missing id attribute\", \"ERROR\")\n            return False\n\n        if market_id not in self.__market_ids:\n            try:\n                # create db and table\n                cursor = self.__attributes_db.cursor()\n\n                # --- ADD PINPOINT LOGS HERE ---\n                self.__log(f\"market {market_id}: creating table with attributes:\", \"DEBUG\")\n                for name, attr in self.__attributes.items():\n                    self.__log(f\"  {name} ({attr[0]}): {repr(attr[1])}\", \"DEBUG\")\n                # --------------------------------\n\n                cursor.execute(self.__create_table_stmt(market_id))\n                self.__attributes_db.commit()\n\n                # insert into main markets.db\n                clobTokenIds1 = self.__attributes[\"clobTokenIds1\"][1]\n                clobTokenIds2 = self.__attributes[\"clobTokenIds2\"][1]\n                negrisk_id = self.__attributes.get(\"negRiskID\", [None, None])[1]\n                now = datetime.now(timezone.utc)\n                iso_str = now.isoformat(timespec=\"microseconds\").replace(\"+00:00\", \"Z\")\n                \n                cursor = self.__markets_db.cursor()\n                cursor.execute(\"\"\"INSERT INTO markets \n                    (collector_version, insert_time, id, clobTokenIds1, clobTokenIds2, negRiskMarketID) \n                    VALUES (?, ?, ?, ?, ?, ?)\"\"\",\n                    (self.__version, iso_str, market_id, clobTokenIds1, clobTokenIds2, negrisk_id))\n                self.__markets_db.commit()\n                self.__log(f\"market_collector table creation successful for market {market_id} at offset {self.__market_offset}\", \"DEBUG\")\n            except Exception as e:\n                self.__log(f\"market_collector failed new market creation for {market_id}: {e}\", \"ERROR\")\n                self.__log(f\"marktet_collector create_table statement: {self.__create_table_stmt(market_id)}\", \"ERROR\")\n                return False\n\n        try:\n            cursor = self.__attributes_db.cursor()\n            cursor.execute(self.__create_insert_stmt(market_id))\n            self.__attributes_db.commit()\n            self.__log(f\"market_collector insert successful for market {market_id} at offset {self.__market_offset}\", \"DEBUG\")\n            return True\n        except Exception as e:\n            self.__log(f\"market collector failed inserting attributes for market {market_id}: {e}\", \"ERROR\")\n            self.__log(f\"marktet_collector insert statement: {self.__create_insert_stmt(market_id)}\", \"ERROR\")\n            #for attr_name, attr in self.__attributes.items():\n               # self.__log(f\"market collector attribute dump: {attr_name}={attr[1]} ({attr[0]})\", \"DEBUG\")\n            #return False", "dependencies": ["asyncio", "time", "datetime", "json", "sqlite3", "os", "aiohttp", "shutil"]}
[Server] Handling add_class for: market_collector
[Server] Dependencies: ['asyncio', 'time', 'datetime', 'json', 'sqlite3', 'os', 'aiohttp', 'shutil']
[Server] Importing dependency: sqlite3
[Server] Importing dependency: aiohttp
[Server] Class market_collector added successfully
[Server] Received message: {"type": "create_instance", "class_name": "market_collector", "instance_name": "market", "args": {}}
[Server] Handling create_instance: market of class market_collector
[Server] Instance market created
[Server] Received message: {"type": "start_instance", "instance_name": "market"}
[Server] Handling start_instance: market
[Server] Instance market started
[INFO] market_collector started
[DEBUG] market_collector fetched 500 markets
[ERROR] market_collector failed to set_attribute for orderPriceMinTickSize and 0.001 of type <class 'float'>
[DEBUG] market_collector exiting running loop due to abort
[DEBUG] market_collector cleanup started
[DEBUG] Closed markets aiohttp client
[DEBUG] Closed markets.db connection
[DEBUG] Closed markets.db connection
[INFO] market_collector cleanup finished
[Server] collection_manager shutting down
